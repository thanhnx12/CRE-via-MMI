{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\conpl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "from sampler import data_sampler\n",
    "from config import Config\n",
    "import torch\n",
    "from model.bert_encoder import Bert_Encoder\n",
    "from model.dropout_layer import Dropout_Layer\n",
    "from model.classifier import Softmax_Layer, Proto_Softmax_Layer\n",
    "from data_loader import get_data_loader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import os\n",
    "# import wandb\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "def train_simple_model(config, encoder, dropout_layer, classifier, training_data, epochs, map_relid2tempid):\n",
    "    data_loader = get_data_loader(config, training_data, shuffle=True)\n",
    "\n",
    "    encoder.train()\n",
    "    dropout_layer.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': encoder.parameters(), 'lr': 0.00001},\n",
    "        {'params': dropout_layer.parameters(), 'lr': 0.00001},\n",
    "        {'params': classifier.parameters(), 'lr': 0.001}\n",
    "    ])\n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        for step, batch_data in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            labels, _, tokens = batch_data\n",
    "            labels = labels.to(config.device)\n",
    "            labels = [map_relid2tempid[x.item()] for x in labels]\n",
    "            labels = torch.tensor(labels).to(config.device)\n",
    "\n",
    "            tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "            reps = encoder(tokens)\n",
    "            reps, _ = dropout_layer(reps)\n",
    "            logits = classifier(reps)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"loss is {np.array(losses).mean()}\")\n",
    "\n",
    "\n",
    "def compute_jsd_loss(m_input):\n",
    "    # m_input: the result of m times dropout after the classifier.\n",
    "    # size: m*B*C\n",
    "    m = m_input.shape[0]\n",
    "    mean = torch.mean(m_input, dim=0)\n",
    "    jsd = 0\n",
    "    for i in range(m):\n",
    "        loss = F.kl_div(F.log_softmax(mean, dim=-1), F.softmax(m_input[i], dim=-1), reduction='none')\n",
    "        loss = loss.sum()\n",
    "        jsd += loss / m\n",
    "    return jsd\n",
    "\n",
    "\n",
    "def contrastive_loss(hidden, labels):\n",
    "\n",
    "    logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    return -(logsoftmax(hidden) * labels).sum() / labels.sum()\n",
    "\n",
    "\n",
    "def construct_hard_triplets(output, labels, relation_data):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    pdist = nn.PairwiseDistance(p=2)\n",
    "    for rep, label in zip(output, labels):\n",
    "        positive_relation_data = relation_data[label.item()]\n",
    "        negative_relation_data = []\n",
    "        for key in relation_data.keys():\n",
    "            if key != label.item():\n",
    "                negative_relation_data.extend(relation_data[key])\n",
    "        positive_distance = torch.stack([pdist(rep.cpu(), p) for p in positive_relation_data])\n",
    "        negative_distance = torch.stack([pdist(rep.cpu(), n) for n in negative_relation_data])\n",
    "        positive_index = torch.argmax(positive_distance)\n",
    "        negative_index = torch.argmin(negative_distance)\n",
    "        positive.append(positive_relation_data[positive_index.item()])\n",
    "        negative.append(negative_relation_data[negative_index.item()])\n",
    "\n",
    "\n",
    "    return positive, negative\n",
    "\n",
    "\n",
    "def train_first(config, encoder, dropout_layer, classifier, training_data, epochs, map_relid2tempid, new_relation_data):\n",
    "    data_loader = get_data_loader(config, training_data, shuffle=True)\n",
    "\n",
    "    encoder.train()\n",
    "    dropout_layer.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': encoder.parameters(), 'lr': 0.00001},\n",
    "        {'params': dropout_layer.parameters(), 'lr': 0.00001},\n",
    "        {'params': classifier.parameters(), 'lr': 0.001}\n",
    "    ])\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        for step, (labels, _, tokens) in enumerate(data_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_all = []\n",
    "            tokens = torch.stack([x.to(config.device) for x in tokens], dim=0)\n",
    "            labels = labels.to(config.device)\n",
    "            origin_labels = labels[:]\n",
    "            labels = [map_relid2tempid[x.item()] for x in labels]\n",
    "            labels = torch.tensor(labels).to(config.device)\n",
    "            reps = encoder(tokens)\n",
    "            outputs,_ = dropout_layer(reps)\n",
    "            positives,negatives = construct_hard_triplets(outputs, origin_labels, new_relation_data)\n",
    "\n",
    "            for _ in range(config.f_pass):\n",
    "                output, output_embedding = dropout_layer(reps)\n",
    "                logits = classifier(output)\n",
    "                logits_all.append(logits)\n",
    "\n",
    "            positives = torch.cat(positives, 0).to(config.device)\n",
    "            negatives = torch.cat(negatives, 0).to(config.device)\n",
    "            anchors = outputs\n",
    "            logits_all = torch.stack(logits_all)\n",
    "            m_labels = labels.expand((config.f_pass, labels.shape[0]))  # m,B\n",
    "            loss1 = criterion(logits_all.reshape(-1, logits_all.shape[-1]), m_labels.reshape(-1))\n",
    "            loss2 = compute_jsd_loss(logits_all)\n",
    "            tri_loss = triplet_loss(anchors, positives, negatives)\n",
    "            loss = loss1 + loss2 + tri_loss\n",
    "\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        print(f\"loss is {np.array(losses).mean()}\")\n",
    "\n",
    "\n",
    "def train_mem_model(config, encoder, dropout_layer, classifier, training_data, epochs, map_relid2tempid, new_relation_data,\n",
    "                prev_encoder, prev_dropout_layer, prev_classifier, prev_relation_index):\n",
    "    data_loader = get_data_loader(config, training_data, shuffle=True)\n",
    "\n",
    "    encoder.train()\n",
    "    dropout_layer.train()\n",
    "    classifier.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': encoder.parameters(), 'lr': 0.00001},\n",
    "        {'params': dropout_layer.parameters(), 'lr': 0.00001},\n",
    "        {'params': classifier.parameters(), 'lr': 0.001}\n",
    "    ])\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    distill_criterion = nn.CosineEmbeddingLoss()\n",
    "    T = config.kl_temp\n",
    "    for epoch_i in range(epochs):\n",
    "        losses = []\n",
    "        for step, (labels, _, tokens) in enumerate(data_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_all = []\n",
    "            tokens = torch.stack([x.to(config.device) for x in tokens], dim=0)\n",
    "            labels = labels.to(config.device)\n",
    "            origin_labels = labels[:]\n",
    "            labels = [map_relid2tempid[x.item()] for x in labels]\n",
    "            labels = torch.tensor(labels).to(config.device)\n",
    "            reps = encoder(tokens)\n",
    "            normalized_reps_emb = F.normalize(reps.view(-1, reps.size()[1]), p=2, dim=1)\n",
    "            outputs,_ = dropout_layer(reps)\n",
    "            if prev_dropout_layer is not None:\n",
    "                prev_outputs, _ = prev_dropout_layer(reps)\n",
    "                positives,negatives = construct_hard_triplets(prev_outputs, origin_labels, new_relation_data)\n",
    "            else:\n",
    "                positives, negatives = construct_hard_triplets(outputs, origin_labels, new_relation_data)\n",
    "\n",
    "            for _ in range(config.f_pass):\n",
    "                output, output_embedding = dropout_layer(reps)\n",
    "                logits = classifier(output)\n",
    "                logits_all.append(logits)\n",
    "\n",
    "            positives = torch.cat(positives, 0).to(config.device)\n",
    "            negatives = torch.cat(negatives, 0).to(config.device)\n",
    "            anchors = outputs\n",
    "            logits_all = torch.stack(logits_all)\n",
    "            m_labels = labels.expand((config.f_pass, labels.shape[0]))  # m,B\n",
    "            loss1 = criterion(logits_all.reshape(-1, logits_all.shape[-1]), m_labels.reshape(-1))\n",
    "            loss2 = compute_jsd_loss(logits_all)\n",
    "            tri_loss = triplet_loss(anchors, positives, negatives)\n",
    "            loss = loss1 + loss2 + tri_loss\n",
    "\n",
    "            if prev_encoder is not None:\n",
    "                prev_reps = prev_encoder(tokens).detach()\n",
    "                normalized_prev_reps_emb = F.normalize(prev_reps.view(-1, prev_reps.size()[1]), p=2, dim=1)\n",
    "\n",
    "                feature_distill_loss = distill_criterion(normalized_reps_emb, normalized_prev_reps_emb,\n",
    "                                                         torch.ones(tokens.size(0)).to(\n",
    "                                                             config.device))\n",
    "                loss += feature_distill_loss\n",
    "\n",
    "            if prev_dropout_layer is not None and prev_classifier is not None:\n",
    "                prediction_distill_loss = None\n",
    "                dropout_output_all = []\n",
    "                prev_dropout_output_all = []\n",
    "                for i in range(config.f_pass):\n",
    "                    output, _ = dropout_layer(reps)\n",
    "                    prev_output, _ = prev_dropout_layer(reps)\n",
    "                    dropout_output_all.append(output)\n",
    "                    prev_dropout_output_all.append(output)\n",
    "                    pre_logits = prev_classifier(output).detach()\n",
    "\n",
    "                    pre_logits = F.softmax(pre_logits.index_select(1, prev_relation_index) / T, dim=1)\n",
    "\n",
    "                    log_logits = F.log_softmax(logits_all[i].index_select(1, prev_relation_index) / T, dim=1)\n",
    "                    if i == 0:\n",
    "                        prediction_distill_loss = -torch.mean(torch.sum(pre_logits * log_logits, dim=1))\n",
    "                    else:\n",
    "                        prediction_distill_loss += -torch.mean(torch.sum(pre_logits * log_logits, dim=1))\n",
    "\n",
    "                prediction_distill_loss /= config.f_pass\n",
    "                loss += prediction_distill_loss\n",
    "                dropout_output_all = torch.stack(dropout_output_all)\n",
    "                prev_dropout_output_all = torch.stack(prev_dropout_output_all)\n",
    "                mean_dropout_output_all = torch.mean(dropout_output_all, dim=0)\n",
    "                mean_prev_dropout_output_all = torch.mean(prev_dropout_output_all,dim=0)\n",
    "                normalized_output = F.normalize(mean_dropout_output_all.view(-1, mean_dropout_output_all.size()[1]), p=2, dim=1)\n",
    "                normalized_prev_output = F.normalize(mean_prev_dropout_output_all.view(-1, mean_prev_dropout_output_all.size()[1]), p=2, dim=1)\n",
    "                hidden_distill_loss = distill_criterion(normalized_output, normalized_prev_output,\n",
    "                                                         torch.ones(tokens.size(0)).to(\n",
    "                                                             config.device))\n",
    "                loss += hidden_distill_loss\n",
    "\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        print(f\"loss is {np.array(losses).mean()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def batch2device(batch_tuple, device):\n",
    "    ans = []\n",
    "    for var in batch_tuple:\n",
    "        if isinstance(var, torch.Tensor):\n",
    "            ans.append(var.to(device))\n",
    "        elif isinstance(var, list):\n",
    "            ans.append(batch2device(var))\n",
    "        elif isinstance(var, tuple):\n",
    "            ans.append(tuple(batch2device(var)))\n",
    "        else:\n",
    "            ans.append(var)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def evaluate_strict_model(config, encoder, dropout_layer, classifier, test_data, seen_relations, map_relid2tempid):\n",
    "    data_loader = get_data_loader(config, test_data, batch_size=1)\n",
    "    encoder.eval()\n",
    "    dropout_layer.eval()\n",
    "    classifier.eval()\n",
    "    n = len(test_data)\n",
    "\n",
    "    correct = 0\n",
    "    for step, batch_data in enumerate(data_loader):\n",
    "        labels, _, tokens = batch_data\n",
    "        labels = labels.to(config.device)\n",
    "        labels = [map_relid2tempid[x.item()] for x in labels]\n",
    "        labels = torch.tensor(labels).to(config.device)\n",
    "\n",
    "        tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "        reps = encoder(tokens)\n",
    "        reps, _ = dropout_layer(reps)\n",
    "        logits = classifier(reps)\n",
    "\n",
    "        seen_relation_ids = [rel2id[relation] for relation in seen_relations]\n",
    "        seen_relation_ids = [map_relid2tempid[relation] for relation in seen_relation_ids]\n",
    "        seen_sim = logits[:,seen_relation_ids].cpu().data.numpy()\n",
    "        max_smi = np.max(seen_sim,axis=1)\n",
    "\n",
    "        label_smi = logits[:,labels].cpu().data.numpy()\n",
    "\n",
    "        if label_smi >= max_smi:\n",
    "            correct += 1\n",
    "\n",
    "    return correct/n\n",
    "\n",
    "\n",
    "def select_data(config, encoder, dropout_layer, relation_dataset):\n",
    "    data_loader = get_data_loader(config, relation_dataset, shuffle=False, drop_last=False, batch_size=1)\n",
    "    features = []\n",
    "    encoder.eval()\n",
    "    dropout_layer.eval()\n",
    "    for step, batch_data in enumerate(data_loader):\n",
    "        labels, _, tokens = batch_data\n",
    "        tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "        with torch.no_grad():\n",
    "            feature = dropout_layer(encoder(tokens))[1].cpu()\n",
    "        features.append(feature)\n",
    "\n",
    "    features = np.concatenate(features)\n",
    "    num_clusters = min(config.num_protos, len(relation_dataset))\n",
    "    distances = KMeans(n_clusters=num_clusters, random_state=0).fit_transform(features)\n",
    "\n",
    "    memory = []\n",
    "    for k in range(num_clusters):\n",
    "        sel_index = np.argmin(distances[:, k])\n",
    "        instance = relation_dataset[sel_index]\n",
    "        memory.append(instance)\n",
    "    return memory\n",
    "\n",
    "\n",
    "def get_proto(config, encoder, dropout_layer, relation_dataset):\n",
    "    data_loader = get_data_loader(config, relation_dataset, shuffle=False, drop_last=False, batch_size=1)\n",
    "    features = []\n",
    "    encoder.eval()\n",
    "    dropout_layer.eval()\n",
    "    for step, batch_data in enumerate(data_loader):\n",
    "        labels, _, tokens = batch_data\n",
    "        tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "        with torch.no_grad():\n",
    "            feature = dropout_layer(encoder(tokens))[1]\n",
    "        features.append(feature)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    proto = torch.mean(features, dim=0, keepdim=True).cpu()\n",
    "    standard = torch.sqrt(torch.var(features, dim=0)).cpu()\n",
    "    return proto, standard\n",
    "\n",
    "\n",
    "def generate_relation_data(protos, relation_standard):\n",
    "    relation_data = {}\n",
    "    relation_sample_nums = 10\n",
    "    for id in protos.keys():\n",
    "        relation_data[id] = []\n",
    "        difference = np.random.normal(loc=0, scale=1, size=relation_sample_nums)\n",
    "        for diff in difference:\n",
    "            relation_data[id].append(protos[id] + diff * relation_standard[id])\n",
    "    return relation_data\n",
    "\n",
    "\n",
    "def generate_current_relation_data(config, encoder, dropout_layer, relation_dataset):\n",
    "    data_loader = get_data_loader(config, relation_dataset, shuffle=False, drop_last=False, batch_size=1)\n",
    "    relation_data = []\n",
    "    encoder.eval()\n",
    "    dropout_layer.eval()\n",
    "    for step, batch_data in enumerate(data_loader):\n",
    "        labels, _, tokens = batch_data\n",
    "        tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "        with torch.no_grad():\n",
    "            feature = dropout_layer(encoder(tokens))[1].cpu()\n",
    "        relation_data.append(feature)\n",
    "    return relation_data\n",
    "\n",
    "from transformers import  BertTokenizer\n",
    "def data_augmentation(config, encoder, train_data, prev_train_data):\n",
    "    expanded_train_data = train_data[:]\n",
    "    expanded_prev_train_data = prev_train_data[:]\n",
    "    encoder.eval()\n",
    "    all_data = train_data + prev_train_data\n",
    "    tokenizer = BertTokenizer.from_pretrained(config.bert_path, additional_special_tokens=[\"[E11]\", \"[E12]\", \"[E21]\", \"[E22]\"])\n",
    "    entity_index = []\n",
    "    entity_mention = []\n",
    "    for sample in all_data:\n",
    "        e11 = sample['tokens'].index(30522)\n",
    "        e12 = sample['tokens'].index(30523)\n",
    "        e21 = sample['tokens'].index(30524)\n",
    "        e22 = sample['tokens'].index(30525)\n",
    "        entity_index.append([e11,e12])\n",
    "        entity_mention.append(sample['tokens'][e11+1:e12])\n",
    "        entity_index.append([e21,e22])\n",
    "        entity_mention.append(sample['tokens'][e21+1:e22])\n",
    "\n",
    "    data_loader = get_data_loader(config, all_data, shuffle=False, drop_last=False, batch_size=1)\n",
    "    features = []\n",
    "    encoder.eval()\n",
    "    for step, batch_data in enumerate(data_loader):\n",
    "        labels, _, tokens = batch_data\n",
    "        tokens = torch.stack([x.to(config.device) for x in tokens],dim=0)\n",
    "        with torch.no_grad():\n",
    "            feature = encoder(tokens)\n",
    "        feature1, feature2 = torch.split(feature, [config.encoder_output_size,config.encoder_output_size], dim=1)\n",
    "        features.append(feature1)\n",
    "        features.append(feature2)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    # similarity_matrix = F.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim=-1)\n",
    "    similarity_matrix = []\n",
    "    for i in range(len(features)):\n",
    "        similarity_matrix.append([0]*len(features))\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        for j in range(i,len(features)):\n",
    "            similarity = F.cosine_similarity(features[i],features[j],dim=0)\n",
    "            similarity_matrix[i][j] = similarity\n",
    "            similarity_matrix[j][i] = similarity\n",
    "\n",
    "    similarity_matrix = torch.tensor(similarity_matrix).to(config.device)\n",
    "    zero = torch.zeros_like(similarity_matrix).to(config.device)\n",
    "    diag = torch.diag_embed(torch.diag(similarity_matrix))\n",
    "    similarity_matrix -= diag\n",
    "    similarity_matrix = torch.where(similarity_matrix<0.95, zero, similarity_matrix)\n",
    "    nonzero_index = torch.nonzero(similarity_matrix)\n",
    "    expanded_train_count = 0\n",
    "\n",
    "    for origin, replace in nonzero_index:\n",
    "        sample_index = int(origin/2)\n",
    "        sample = all_data[sample_index]\n",
    "        if entity_mention[origin] == entity_mention[replace]:\n",
    "            continue\n",
    "        new_tokens = sample['tokens'][:entity_index[origin][0]+1] + entity_mention[replace] + sample['tokens'][entity_index[origin][1]:]\n",
    "        if len(new_tokens) < config.max_length:\n",
    "            new_tokens = new_tokens + [0]*(config.max_length-len(new_tokens))\n",
    "        else:\n",
    "            new_tokens = new_tokens[:config.max_length]\n",
    "\n",
    "        new_sample = {\n",
    "            'relation': sample['relation'],\n",
    "            'neg_labels': sample['neg_labels'],\n",
    "            'tokens': new_tokens\n",
    "        }\n",
    "        if sample_index < len(train_data) and expanded_train_count < 5 * len(train_data):\n",
    "            expanded_train_data.append(new_sample)\n",
    "            expanded_train_count += 1\n",
    "        else:\n",
    "            expanded_prev_train_data.append(new_sample)\n",
    "    return expanded_train_data, expanded_prev_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    task = \"fewrel\"\n",
    "    shot = 5\n",
    "    config = 'config.ini'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(args.config)\n",
    "config.device = torch.device(config.device)\n",
    "config.n_gpu = torch.cuda.device_count()\n",
    "config.batch_size_per_step = int(config.batch_size / config.gradient_accumulation_steps)\n",
    "\n",
    "config.task = args.task\n",
    "config.shot = args.shot\n",
    "config.step1_epochs = 5\n",
    "config.step2_epochs = 15\n",
    "config.step3_epochs = 20\n",
    "config.temperature = 0.08\n",
    "\n",
    "if config.task == \"FewRel\":\n",
    "    config.relation_file = \"data/fewrel/relation_name.txt\"\n",
    "    config.rel_index = \"data/fewrel/rel_index.npy\"\n",
    "    config.rel_feature = \"data/fewrel/rel_feature.npy\"\n",
    "    config.rel_des_file = \"data/fewrel/relation_description.txt\"\n",
    "    config.num_of_relation = 80\n",
    "    if config.shot == 5:\n",
    "        config.rel_cluster_label = \"data/fewrel/CFRLdata_10_100_10_5/rel_cluster_label_0.npy\"\n",
    "        config.training_file = \"data/fewrel/CFRLdata_10_100_10_5/train_0.txt\"\n",
    "        config.valid_file = \"data/fewrel/CFRLdata_10_100_10_5/valid_0.txt\"\n",
    "        config.test_file = \"data/fewrel/CFRLdata_10_100_10_5/test_0.txt\"\n",
    "    elif config.shot == 10:\n",
    "        config.rel_cluster_label = \"data/fewrel/CFRLdata_10_100_10_10/rel_cluster_label_0.npy\"\n",
    "        config.training_file = \"data/fewrel/CFRLdata_10_100_10_10/train_0.txt\"\n",
    "        config.valid_file = \"data/fewrel/CFRLdata_10_100_10_10/valid_0.txt\"\n",
    "        config.test_file = \"data/fewrel/CFRLdata_10_100_10_10/test_0.txt\"\n",
    "    else:\n",
    "        config.rel_cluster_label = \"data/fewrel/CFRLdata_10_100_10_2/rel_cluster_label_0.npy\"\n",
    "        config.training_file = \"data/fewrel/CFRLdata_10_100_10_2/train_0.txt\"\n",
    "        config.valid_file = \"data/fewrel/CFRLdata_10_100_10_2/valid_0.txt\"\n",
    "        config.test_file = \"data/fewrel/CFRLdata_10_100_10_2/test_0.txt\"\n",
    "else:\n",
    "    config.relation_file = \"data/tacred/relation_name.txt\"\n",
    "    config.rel_index = \"data/tacred/rel_index.npy\"\n",
    "    config.rel_feature = \"data/tacred/rel_feature.npy\"\n",
    "    config.num_of_relation = 41\n",
    "    if config.shot == 5:\n",
    "        config.rel_cluster_label = \"data/tacred/CFRLdata_10_100_10_5/rel_cluster_label_0.npy\"\n",
    "        config.training_file = \"data/tacred/CFRLdata_10_100_10_5/train_0.txt\"\n",
    "        config.valid_file = \"data/tacred/CFRLdata_10_100_10_5/valid_0.txt\"\n",
    "        config.test_file = \"data/tacred/CFRLdata_10_100_10_5/test_0.txt\"\n",
    "    else:\n",
    "        config.rel_cluster_label = \"data/tacred/CFRLdata_10_100_10_10/rel_cluster_label_0.npy\"\n",
    "        config.training_file = \"data/tacred/CFRLdata_10_100_10_10/train_0.txt\"\n",
    "        config.valid_file = \"data/tacred/CFRLdata_10_100_10_10/valid_0.txt\"\n",
    "        config.test_file = \"data/tacred/CFRLdata_10_100_10_10/test_0.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 5 2 1 0 3 4]\n"
     ]
    }
   ],
   "source": [
    "sampler = data_sampler(config=config, seed=config.seed+100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person countries of residence', 'organization top members employees', 'organization member of', 'person origin', 'person title', 'organization country of headquarters']\n",
      "['person stateorprovinces of residence', 'person date of death', 'organization number of employees members', 'person alternate names', 'person spouse']\n",
      "['person date of birth', 'person stateorprovince of birth', 'person parents', 'person employee of', 'person stateorprovince of death']\n",
      "['person cities of residence', 'person schools attended', 'person country of death', 'person children', 'person charges']\n",
      "['organization subsidiaries', 'organization parents', 'organization alternate names', 'organization city of headquarters', 'person siblings']\n",
      "['person country of birth', 'organization website', 'organization shareholders', 'organization dissolved', 'organization founded by']\n",
      "['person cause of death', 'organization political religious affiliation', 'organization stateorprovince of headquarters', 'person other family', 'person city of death']\n",
      "['organization founded', 'person age', 'person city of birth', 'organization members', 'person religion']\n"
     ]
    }
   ],
   "source": [
    "data  = []\n",
    "for steps, (training_data, valid_data, test_data, current_relations, historic_test_data, seen_relations) in enumerate(sampler):\n",
    "            print(current_relations)\n",
    "            data.append((training_data, valid_data, test_data, current_relations, historic_test_data, seen_relations))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2268, 1011, 5757, 1011, 6021, 2102, 2692, 2549, 1024, 5354, 1024, 2184, 4012, 1028, 2626, 1024, 9587, 14945, 25353, 10936, 3669, 25886, 1026, 25353, 10936, 1030, 20643, 9006, 1028, 8299, 1024, 1013, 1013, 7479, 29337, 28251, 8586, 5358, 1013, 3422, 1029, 1058, 1027, 1053, 2063, 2620, 4328, 2629, 2497, 2860, 2683, 16409, 9587, 14945, 25353, 10936, 3669, 25886, 1026, 25353, 10936, 1030, 20643, 9006, 1028, 8299, 1024, 1013, 1013, 2739, 15396, 5643, 9006, 1013, 2739, 1013, 4021, 5643, 1003, 1016, 24700, 7974, 2015, 1013, 6027, 1013, 2466, 1013, 17350, 23809, 2100, 28332, 4274, 2003, 6179, 2005, 2437, 1996, 3606, 2124, 1010, 2758, 2852, 24404, 15222, 2099, 1036, 1036, 15490, 17761, 1010, 2238, 1015, 1011, 1048, 15185, 1011, 30522, 16595, 8067, 30523, 1011, 25269, 2497, 1011, 1011, 102]\n",
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(data)):\n",
    "    train_data = []\n",
    "    for i in range(len(list(data[j][0].values()))):\n",
    "        train_data.extend(list(data[j][0].values())[i])\n",
    "    cnt = 0\n",
    "    for x in train_data:\n",
    "        if 30524 not in x['tokens']:\n",
    "            cnt +=1\n",
    "            print(x['tokens'])\n",
    "    if cnt > 0:\n",
    "        print(j)\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (942630328.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    delete x\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argwhere(tokens == 30524).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '2009', '-', '06', '-', '03', '##t', '##0', '##4', ':', '59', ':', '10', 'com', '>', 'wrote', ':', 'mo', '##hd', 'sy', '##az', '##li', 'mahmud', '<', 'sy', '##az', '@', 'yahoo', '##com', '>', 'http', ':', '/', '/', 'www', '##you', '##tub', '##ec', '##om', '/', 'watch', '?', 'v', '=', 'q', '##e', '##8', '##mi', '##5', '##b', '##w', '##9', '##dc', 'mo', '##hd', 'sy', '##az', '##li', 'mahmud', '<', 'sy', '##az', '@', 'yahoo', '##com', '>', 'http', ':', '/', '/', 'news', '##asia', '##one', '##com', '/', 'news', '/', 'asia', '##one', '%', '2', '##bn', '##ew', '##s', '/', 'malaysia', '/', 'story', '/', 'a1', '##stor', '##y', '##200', 'internet', 'is', 'useful', 'for', 'making', 'the', 'truth', 'known', ',', 'says', 'dr', 'maha', '##thi', '##r', '`', '`', 'kuala', 'lumpur', ',', 'june', '1', '-', 'l', '##rb', '-', '[E11]', 'bern', '##ama', '[E12]', '-', 'rr', '##b', '-', '-', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config.bert_path, additional_special_tokens=[\"[E11]\", \"[E12]\", \"[E21]\", \"[E22]\"])\n",
    "tokens = [101, 2268, 1011, 5757, 1011, 6021, 2102, 2692, 2549, 1024, 5354, 1024, 2184, 4012, 1028, 2626, 1024, 9587, 14945, 25353, 10936, 3669, 25886, 1026, 25353, 10936, 1030, 20643, 9006, 1028, 8299, 1024, 1013, 1013, 7479, 29337, 28251, 8586, 5358, 1013, 3422, 1029, 1058, 1027, 1053, 2063, 2620, 4328, 2629, 2497, 2860, 2683, 16409, 9587, 14945, 25353, 10936, 3669, 25886, 1026, 25353, 10936, 1030, 20643, 9006, 1028, 8299, 1024, 1013, 1013, 2739, 15396, 5643, 9006, 1013, 2739, 1013, 4021, 5643, 1003, 1016, 24700, 7974, 2015, 1013, 6027, 1013, 2466, 1013, 17350, 23809, 2100, 28332, 4274, 2003, 6179, 2005, 2437, 1996, 3606, 2124, 1010, 2758, 2852, 24404, 15222, 2099, 1036, 1036, 15490, 17761, 1010, 2238, 1015, 1011, 1048, 15185, 1011, 30522, 16595, 8067, 30523, 1011, 25269, 2497, 1011, 1011, 102]\n",
    "print(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 2009 - 06 - 03t04 : 59 : 10 com > wrote : mohd syazli mahmud < syaz @ yahoocom > http : / / wwwyoutubecom / watch? v = qe8mi5bw9dc mohd syazli mahmud < syaz @ yahoocom > http : / / newsasiaonecom / news / asiaone % 2bnews / malaysia / story / a1story200 internet is useful for making the truth known, says dr mahathir ` ` kuala lumpur, june 1 - lrb - [E11] bernama [E12] - rrb - - [SEP]'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x in train_data:\n",
    "    if 30524 not in x['tokens']:\n",
    "       cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config.bert_path, additional_special_tokens=[\"[E11]\", \"[E12]\", \"[E21]\", \"[E22]\"])\n",
    "tokenizer.convert_tokens_to_ids(\"[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "text = [\"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [MASK] created the Muppets . [SEP]\", \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [MASK] created the Muppets . [SEP]\"]\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)\n",
    "output = model(input_ids, return_dict=True)\n",
    "logits = output.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[101, 100, 100, 102]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 2\u001b[0m mask_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m103\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "tokens = input_ids.tolist()\n",
    "mask_idx = np.argwhere(np.array(tokens) == 103)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_output = []\n",
    "\n",
    "for i in range(input_ids.shape[0]):\n",
    "    instance_output = torch.index_select(logits, 0, torch.tensor(i))\n",
    "    instance_output = torch.index_select(instance_output, 1, torch.tensor(mask_idx))\n",
    "    mask_output.append(instance_output)\n",
    "mask_output = torch.cat(mask_output, dim=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 30522])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bert_EncoderMLM\n\u001b[0;32m      3\u001b[0m config\u001b[38;5;241m.\u001b[39mpattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_marker_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBert_EncoderMLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thanh\\OneDrive\\Desktop\\DATN\\SCKD\\model\\bert_encoder.py:86\u001b[0m, in \u001b[0;36mBert_EncoderMLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28msuper\u001b[39m(Bert_EncoderMLM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mBertForMaskedLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_config \u001b[38;5;241m=\u001b[39m BertForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mbert_path)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# the dimension for the final outputs\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\conpl\\lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import model.bert_encoder\n",
    "from model.bert_encoder import Bert_EncoderMLM\n",
    "config.pattern = \"entity_marker_mask\"\n",
    "model = Bert_EncoderMLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "config = Config('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'infonce_temprature'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfonce_temprature\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Config' object has no attribute 'infonce_temprature'"
     ]
    }
   ],
   "source": [
    "config.infonce_temprature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_special_tokens = [\"[E11]\", \"[E12]\", \"[E21]\", \"[E22]\"]\n",
    "additional_special_tokens.extend([f\"[REL{i}]\" for i in range(1, 50 + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', additional_special_tokens=additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"[REL1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3) + 1e8\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = torch.rand(1,3000)\n",
    "C = torch.rand(5,768)\n",
    "W = torch.rand(3000,768)\n",
    "output = torch.matmul(V,W)\n",
    "output = torch.matmul(output,C.T)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,1)\n",
    "b = torch.rand(1,5)\n",
    "temp = torch.cat([a,b],dim=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "output = m(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1380, 0.1012, 0.2047, 0.1749, 0.1983, 0.1830])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(1.0)\n",
    "b = torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0674, 0.6470, 0.4542])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a.unsqueeze(0),b],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1736, 0.1032, 0.3244, 0.1839, 0.0675, 0.1473])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tensor([61.01224136352539 ,-23.5942, 162.7764,  70.3629, -92.8090,  34.2552])\n",
    "m(h/abs(h).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3748, -0.1449,  1.0000,  0.4323, -0.5702,  0.2104])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h/abs(h).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 61.0122,  23.5942, 162.7764,  70.3629,  92.8090,  34.2552])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanh/miniconda3/envs/sckd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 420M/420M [00:40<00:00, 10.8MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls.predictions.bias\n",
      "cls.predictions.transform.dense.weight\n",
      "cls.predictions.transform.dense.bias\n",
      "cls.predictions.transform.LayerNorm.weight\n",
      "cls.predictions.transform.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if \"cls\" in n:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FREEZE LM HEAD \n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from encode import BERTMLMSentenceEncoderPrompt\n",
    "from dataprocess import data_sampler_bert_prompt_deal_first_task_sckd\n",
    "from model import proto_softmax_layer_bertmlm_prompt\n",
    "from dataprocess import get_data_loader_bert_prompt\n",
    "from util import set_seed\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "wandb.login(\n",
    "    anonymous = 'allow',\n",
    "    relogin = True,\n",
    "    key = '9e33535aa8c9fcaa7fc1dfa97a70d9de5107ad37'\n",
    ")\n",
    "\n",
    "def eval_model(config, basemodel, test_set, mem_relations,seen_relations_ids):\n",
    "    basemodel.eval()\n",
    "\n",
    "    test_dataloader = get_data_loader_bert_prompt(config, test_set, shuffle=False, batch_size=30)\n",
    "    allnum= 0.0\n",
    "    correctnum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for step, (labels, neg_labels, sentences, firstent, firstentindex, secondent, secondentindex, headid, tailid, rawtext, lengths,\n",
    "                typelabels, masks, mask_pos) in enumerate(test_dataloader):\n",
    "\n",
    "            sentences = sentences.to(config['device'])\n",
    "            masks = masks.to(config['device'])\n",
    "            mask_pos = mask_pos.to(config['device'])\n",
    "            logits, rep , _ = basemodel(sentences, masks, mask_pos)\n",
    "\n",
    "            distances = basemodel.get_mem_feature(rep)\n",
    "            short_logits = distances\n",
    "\n",
    "            \n",
    "            for index, logit in enumerate(logits):\n",
    "                score = short_logits[index]  # logits[index] + short_logits[index] + long_logits[index]\n",
    "                allnum += 1.0\n",
    "\n",
    "                golden_score = score[labels[index]]\n",
    "                max_neg_score = -2147483647.0\n",
    "                for i in seen_relations_ids :\n",
    "                    if (i != labels[index]) and score[i] > max_neg_score:\n",
    "                        max_neg_score = score[i]\n",
    "                if golden_score >= max_neg_score:\n",
    "                    correctnum += 1\n",
    "\n",
    "    acc = correctnum / allnum\n",
    "    basemodel.train()\n",
    "    return acc\n",
    "\n",
    "def get_memory(config, model, proto_set):\n",
    "    memset = []\n",
    "    resset = []\n",
    "    rangeset= [0]\n",
    "    for i in proto_set:\n",
    "        memset += i\n",
    "        rangeset.append(rangeset[-1] + len(i))\n",
    "    data_loader = get_data_loader_bert_prompt(config, memset, False, False)\n",
    "    features = []\n",
    "    for step, (labels, neg_labels, sentences, firstent, firstentindex, secondent, secondentindex, headid, tailid, rawtext, lengths,\n",
    "               typelabels, masks, mask_pos) in enumerate(data_loader):\n",
    "        sentences = sentences.to(config['device'])\n",
    "        masks = masks.to(config['device'])\n",
    "        mask_pos = mask_pos.to(config['device'])\n",
    "        feature = model.get_feature(sentences, masks, mask_pos)\n",
    "        features.append(feature)\n",
    "    features = np.concatenate(features)\n",
    "\n",
    "    protos = []\n",
    "    for i in range(len(proto_set)):\n",
    "        protos.append(torch.tensor(features[rangeset[i]:rangeset[i+1],:].mean(0, keepdims = True)))\n",
    "    protos = torch.cat(protos, 0)\n",
    "    return protos\n",
    "\n",
    "def select_data(mem_set, proto_memory, config, model, divide_train_set, num_sel_data, current_relations, selecttype):\n",
    "    ####select data according to selecttype\n",
    "    #selecttype is 0: cluster for every rel\n",
    "    #selecttype is 1: use ave embedding\n",
    "    rela_num = len(current_relations)\n",
    "    for i in range(0, rela_num):\n",
    "        thisrel = current_relations[i]\n",
    "        if thisrel in mem_set.keys():\n",
    "            #print(\"have set mem before\")\n",
    "            mem_set[thisrel] = {'0': [], '1': {'h': [], 't': []}}\n",
    "            proto_memory[thisrel] = []\n",
    "        else:\n",
    "            mem_set[thisrel] = {'0': [], '1': {'h': [], 't': []}}\n",
    "        thisdataset = divide_train_set[thisrel]\n",
    "        data_loader = get_data_loader_bert_prompt(config, thisdataset, False, False)\n",
    "        features = []\n",
    "        for step, (labels, neg_labels, sentences, firstent, firstentindex, secondent, secondentindex, headid, tailid, rawtext, lengths,\n",
    "                typelabels, masks, mask_pos) in enumerate(data_loader):\n",
    "            sentences = sentences.to(config['device'])\n",
    "            masks = masks.to(config['device'])\n",
    "            mask_pos = mask_pos.to(config['device'])\n",
    "            feature = model.get_feature(sentences, masks, mask_pos)\n",
    "            features.append(feature)\n",
    "        features = np.concatenate(features)\n",
    "        num_clusters = min(num_sel_data, len(thisdataset))\n",
    "        if selecttype == 0:\n",
    "            kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "            distances = kmeans.fit_transform(features)\n",
    "            for i in range(num_clusters):\n",
    "                sel_index = np.argmin(distances[:, i])\n",
    "                instance = thisdataset[sel_index]\n",
    "                ###change tylelabel\n",
    "                instance[11] = 3\n",
    "                ###add to mem data\n",
    "                mem_set[thisrel]['0'].append(instance)  ####positive sample\n",
    "                cluster_center = kmeans.cluster_centers_[i]\n",
    "                proto_memory[thisrel].append(instance)\n",
    "        elif selecttype == 1:\n",
    "            #print(\"use average embedding\")\n",
    "            samplenum = features.shape[0]\n",
    "            veclength = features.shape[1]\n",
    "            sumvec = np.zeros(veclength)\n",
    "            for j in range(samplenum):\n",
    "                sumvec += features[j]\n",
    "            sumvec /= samplenum\n",
    "\n",
    "            ###find nearest sample\n",
    "            mindist = 100000000\n",
    "            minindex = -100\n",
    "            for j in range(samplenum):\n",
    "                dist = np.sqrt(np.sum(np.square(features[j] - sumvec)))\n",
    "                if dist < mindist:\n",
    "                    minindex = j\n",
    "                    mindist = dist\n",
    "            #print(minindex)\n",
    "            instance = thisdataset[j]\n",
    "            ###change tylelabel\n",
    "            instance[11] = 3\n",
    "            mem_set[thisrel]['0'].append(instance)\n",
    "            proto_memory[thisrel].append(instance)\n",
    "        else:\n",
    "            print(\"error select type\")\n",
    "    #####to get negative sample  mem_set[thisrel]['1']\n",
    "    if rela_num > 1:\n",
    "        ####we need to sample negative samples\n",
    "        allnegres = {}\n",
    "        for i in range(rela_num):\n",
    "            thisnegres = {'h':[],'t':[]}\n",
    "            currel = current_relations[i]\n",
    "            thisrelposnum = len(mem_set[currel]['0'])\n",
    "            #assert thisrelposnum == num_sel_data\n",
    "            #allnum = list(range(thisrelposnum))\n",
    "            for j in range(thisrelposnum):\n",
    "                thisnegres['h'].append(mem_set[currel]['0'][j][3])\n",
    "                thisnegres['t'].append(mem_set[currel]['0'][j][5])\n",
    "            allnegres[currel] = thisnegres\n",
    "        ####get neg sample\n",
    "        for i in range(rela_num):\n",
    "            togetnegindex = (i + 1) % rela_num\n",
    "            togetnegrelname = current_relations[togetnegindex]\n",
    "            mem_set[current_relations[i]]['1']['h'].extend(allnegres[togetnegrelname]['h'])\n",
    "            mem_set[current_relations[i]]['1']['t'].extend(allnegres[togetnegrelname]['t'])\n",
    "    return mem_set\n",
    "\n",
    "def select_data_all(mem_set, proto_memory, config, model, divide_train_set, num_sel_data, current_relations, selecttype):\n",
    "    ####select data according to selecttype\n",
    "    #selecttype is 0: cluster for every rel\n",
    "    #selecttype is 1: use ave embedding\n",
    "    rela_num = len(current_relations)\n",
    "    for i in range(0, rela_num):\n",
    "        thisrel = current_relations[i]\n",
    "        if thisrel in mem_set.keys():\n",
    "            #print(\"have set mem before\")\n",
    "            mem_set[thisrel] = {'0': [], '1': {'h': [], 't': []}}\n",
    "            proto_memory[thisrel].pop()\n",
    "        else:\n",
    "            mem_set[thisrel] = {'0': [], '1': {'h': [], 't': []}}\n",
    "        thisdataset = divide_train_set[thisrel]\n",
    "        # print(len(thisdataset))\n",
    "        for i in range(len(thisdataset)):\n",
    "            instance = thisdataset[i]\n",
    "            ###change tylelabel\n",
    "            instance[11] = 3\n",
    "            ###add to mem data\n",
    "            mem_set[thisrel]['0'].append(instance)\n",
    "            proto_memory[thisrel].append(instance)\n",
    "    if rela_num > 1:\n",
    "        ####we need to sample negative samples\n",
    "        allnegres = {}\n",
    "        for i in range(rela_num):\n",
    "            thisnegres = {'h':[],'t':[]}\n",
    "            currel = current_relations[i]\n",
    "            thisrelposnum = len(mem_set[currel]['0'])\n",
    "            #assert thisrelposnum == num_sel_data\n",
    "            #allnum = list(range(thisrelposnum))\n",
    "            for j in range(thisrelposnum):\n",
    "                thisnegres['h'].append(mem_set[currel]['0'][j][3])\n",
    "                thisnegres['t'].append(mem_set[currel]['0'][j][5])\n",
    "            allnegres[currel] = thisnegres\n",
    "        ####get neg sample\n",
    "        for i in range(rela_num):\n",
    "            togetnegindex = (i + 1) % rela_num\n",
    "            togetnegrelname = current_relations[togetnegindex]\n",
    "            mem_set[current_relations[i]]['1']['h'].extend(allnegres[togetnegrelname]['h'])\n",
    "            mem_set[current_relations[i]]['1']['t'].extend(allnegres[togetnegrelname]['t'])\n",
    "    return mem_set\n",
    "\n",
    "def train_model_with_hard_neg(config, model, mem_set, traindata, epochs, current_proto, seen_relation_ids, tokenizer, ifnegtive=0, threshold=0.2, use_loss5=True, only_mem=False):\n",
    "    print('training data num: ' + str(len(traindata)))\n",
    "    mem_data = []\n",
    "    if len(mem_set) != 0:\n",
    "        for key in mem_set.keys():\n",
    "            mem_data.extend(mem_set[key]['0'])\n",
    "    print('memory data num: '+ str(len(mem_data)))\n",
    "    if only_mem==True:\n",
    "        train_set = mem_data\n",
    "    else:\n",
    "        train_set = traindata + mem_data\n",
    "    print('all train data: ' + str(len(train_set)))\n",
    "    data_loader = get_data_loader_bert_prompt(config, train_set, batch_size=config['batch_size_per_step'])\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    mseloss = nn.MSELoss()\n",
    "    softmax = nn.Softmax(dim=0)\n",
    "    lossfn = nn.MultiMarginLoss(margin=0.2)\n",
    "    optimizer = optim.Adam(model.parameters(), config['learning_rate'])\n",
    "    for epoch_i in range(epochs):\n",
    "        model.set_memorized_prototypes_midproto(current_proto)\n",
    "        losses1 = []\n",
    "        losses2 = []\n",
    "        losses3 = []\n",
    "        losses4 = []\n",
    "        losses5 = []\n",
    "        losses6 = []\n",
    "\n",
    "        lossesfactor1 = 0.0\n",
    "        lossesfactor2 = 1.0\n",
    "        lossesfactor3 = 1.0\n",
    "        lossesfactor4 = 0.0\n",
    "        if use_loss5 == True:\n",
    "            lossesfactor5 = 1.0\n",
    "        else:\n",
    "            lossesfactor5 = 0.0\n",
    "        lossesfactor6 = 0.0\n",
    "        for step, (labels, neg_labels, sentences, firstent, firstentindex, secondent, secondentindex, headid, tailid, rawtext, lengths,\n",
    "            typelabels, masks, mask_pos) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            labels = labels.to(config['device'])\n",
    "            typelabels = typelabels.to(config['device'])  ####0:rel  1:pos(new train data)  2:neg  3:mem\n",
    "            numofmem = 0\n",
    "            numofnewtrain = 0\n",
    "            allnum = 0\n",
    "            memindex = []\n",
    "            for index,onetype in enumerate(typelabels):\n",
    "                if onetype == 1:\n",
    "                    numofnewtrain += 1\n",
    "                if onetype == 3:\n",
    "                    numofmem += 1\n",
    "                    memindex.append(index)\n",
    "                allnum += 1\n",
    "\n",
    "            sentences = sentences.to(config['device'])\n",
    "            masks = masks.to(config['device'])\n",
    "            mask_pos = mask_pos.to(config['device'])\n",
    "            logits, rep , lmhead_output = model(sentences, masks, mask_pos)\n",
    "            logits_proto = model.mem_forward(rep)\n",
    "\n",
    "            loss1 = criterion(logits, labels)\n",
    "            loss2 = criterion(logits_proto, labels)\n",
    "            loss4 = lossfn(logits_proto, labels)\n",
    "            loss3 = torch.tensor(0.0).to(config['device'])\n",
    "            for index, logit in enumerate(logits):\n",
    "                score = logits_proto[index]\n",
    "                preindex = labels[index]\n",
    "                maxscore = score[preindex]\n",
    "                size = score.shape[0]\n",
    "                maxsecondmax = [maxscore]\n",
    "                secondmax = -100000\n",
    "                for j in range(size):\n",
    "                    if j != preindex and score[j] > secondmax:\n",
    "                        secondmax = score[j]\n",
    "                maxsecondmax.append(secondmax)\n",
    "                for j in range(size):\n",
    "                    if j != preindex and maxscore - score[j] < threshold:\n",
    "                        maxsecondmax.append(score[j])\n",
    "                maxsecond = torch.stack(maxsecondmax, 0)\n",
    "                maxsecond = torch.unsqueeze(maxsecond, 0)\n",
    "                la = torch.tensor([0]).to(config['device'])\n",
    "                loss3 += criterion(maxsecond, la)\n",
    "            loss3 /= logits.shape[0]\n",
    "            \n",
    "            loss5 = torch.tensor(0.0).to(config['device'])\n",
    "            allusenum5 = 0\n",
    "            # # --- test---\n",
    "            # try:\n",
    "            #     print(\"Prototype : \")\n",
    "            #     print(model.prototypes.shape)\n",
    "            # except:\n",
    "            #     print(\"no model.prototypes\")\n",
    "            # # --- test---\n",
    "                \n",
    "            # --- add info_nce loss ---\n",
    "            prototypes = model.prototypes.clone()\n",
    "            infoNCE_loss = 0\n",
    "            try:\n",
    "                for i in range(rep.shape[0]):\n",
    "                    neg_prototypes = [prototypes[rel_id] for rel_id in seen_relations_ids if rel_id != labels[i].item()]\n",
    "                    neg_prototypes = torch.stack(neg_prototypes)\n",
    "                    neg_prototypes.requires_grad_ = False\n",
    "                    neg_prototypes = neg_prototypes.squeeze() # [num_neg_prototypes, dim]\n",
    "\n",
    "                    f_pos = model.sentence_encoder.infoNCE_f(lmhead_output[i],rep[i] , temperature = config['infonce_temperature'])\n",
    "                    f_neg = model.sentence_encoder.infoNCE_f(lmhead_output[i],neg_prototypes , temperature = config['infonce_temperature'])\n",
    "                    f_concat = torch.cat([f_pos.unsqueeze(0),f_neg],dim = 0)\n",
    "\n",
    "                    f_concat = torch.log(torch.max(f_concat , torch.tensor(1e-9).to(config.device)))\n",
    "\n",
    "                    infoNCE_loss += -torch.log(softmax(f_concat)[0])\n",
    "            except Exception as e:\n",
    "                print(e.with_traceback())\n",
    "                print(\"no infoNCE_loss\")\n",
    "            infoNCE_loss /= rep.shape[0]\n",
    "            # --- add info_nce loss ---\n",
    "\n",
    "            # --- add mlm loss ---\n",
    "            mlm_labels = labels + 30522 - 1\n",
    "            mlm_labels = mlm_labels.to(config['device'])\n",
    "            mlm_labels.requires_grad = False\n",
    "            mlm_loss = criterion(lmhead_output,mlm_labels)\n",
    "            # --- add mlm loss ---\n",
    "            for index in memindex:\n",
    "                preindex = labels[index]\n",
    "                if preindex in model.haveseenrelations:\n",
    "                    loss5 += mseloss(softmax(rep[index]), softmax(model.prototypes[preindex]))\n",
    "                allusenum5 += 1\n",
    "            \n",
    "            loss6 = torch.tensor(0.0).to(config['device'])\n",
    "            allusenum6 = 0\n",
    "            for index in memindex:\n",
    "                preindex = labels[index]\n",
    "                if preindex in model.haveseenrelations:\n",
    "                    best_distrbution = model.mem_forward_update(rep[index].view(1, -1), model.bestproto)\n",
    "                    current_distrbution = model.mem_forward_update(model.prototypes[preindex].view(1, -1), model.bestproto)\n",
    "                    loss6 += mseloss(best_distrbution, current_distrbution)\n",
    "                allusenum6 += 1\n",
    "            \n",
    "            if len(memindex) == 0:\n",
    "                loss = loss1 * lossesfactor1 + loss2 * lossesfactor2 + loss3 * lossesfactor3 + loss4 * lossesfactor4\n",
    "            else:\n",
    "                loss5 = loss5 / allusenum5\n",
    "                loss6 = loss6 / allusenum6\n",
    "                loss = loss1 * lossesfactor1 + loss2 * lossesfactor2 + loss3 * lossesfactor3 + loss4 * lossesfactor4 + loss5 * lossesfactor5 + loss6 * lossesfactor6   + infoNCE_loss * config['infonce_lossfactor'] + mlm_loss * config['mlm_lossfactor']###with loss5\n",
    "            loss.backward()\n",
    "            losses1.append(loss1.item())\n",
    "            losses2.append(loss2.item())\n",
    "            losses3.append(loss3.item())\n",
    "            losses4.append(loss4.item())\n",
    "            losses5.append(loss5.item())\n",
    "            losses6.append(loss6.item())\n",
    "            # print(f\" InfoNCE_loss: {infoNCE_loss.item()} , mlm_loss: {mlm_loss.item()}\")\n",
    "            wandb.log({\"Loss1\": loss1.item(), \"Loss2\": loss2.item(), \"Loss3\": loss3.item(), \"Loss4\": loss4.item(), \"Loss5\": loss5.item(), \"Loss6\": loss6.item(), \"InfoNCE_loss\": infoNCE_loss.item(), \"mlm_loss\": mlm_loss.item()})\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])#cxd\n",
    "            optimizer.step()\n",
    "        return model\n",
    "\n",
    "def train_memory(config, model, mem_set, train_set, epochs, current_proto, original_vocab_size,seen_relation_ids, ifusemem=True, threshold=0.2):\n",
    "    train_set = []\n",
    "    if ifusemem:\n",
    "        mem_data = []\n",
    "        if len(mem_set)!=0:\n",
    "            for key in mem_set.keys():\n",
    "                mem_data.extend(mem_set[key]['0'])\n",
    "        train_set.extend(mem_data)\n",
    "    data_loader = get_data_loader_bert_prompt(config, train_set, batch_size = config['batch_size_per_step'])\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    mseloss = nn.MSELoss()\n",
    "    softmax = nn.Softmax(dim=0)\n",
    "    lossfn = nn.MultiMarginLoss(margin=0.2)\n",
    "    optimizer = optim.Adam(model.parameters(), config['learning_rate'])#cxd\n",
    "    for epoch_i in range(epochs):\n",
    "        model.set_memorized_prototypes_midproto(current_proto)\n",
    "        losses1 = []\n",
    "        losses2 = []\n",
    "        losses3 = []\n",
    "        losses4 = []\n",
    "        losses5 = []\n",
    "        losses6 = []\n",
    "\n",
    "        lossesfactor1 = 0.0\n",
    "        lossesfactor2 = 1.0\n",
    "        lossesfactor3 = 1.0\n",
    "        lossesfactor4 = 0.0\n",
    "        lossesfactor5 = 1.0\n",
    "        lossesfactor6 = 1.0\n",
    "\n",
    "        for step, (labels, neg_labels, sentences, firstent, firstentindex, secondent, secondentindex, headid, tailid, rawtext,\n",
    "                   lengths, typelabels, masks, mask_pos) in enumerate(tqdm(data_loader)):\n",
    "            model.zero_grad()\n",
    "            sentences = sentences.to(config['device'])\n",
    "            masks = masks.to(config['device'])\n",
    "            mask_pos = mask_pos.to(config['device'])\n",
    "            logits, rep , lmhead_output = model(sentences, masks, mask_pos)\n",
    "            logits_proto = model.mem_forward(rep)\n",
    "\n",
    "            labels = labels.to(config['device'])\n",
    "            loss1 = criterion(logits, labels)\n",
    "            loss2 = criterion(logits_proto, labels)\n",
    "            loss4 = lossfn(logits_proto, labels)\n",
    "            loss3 = torch.tensor(0.0).to(config['device'])\n",
    "            ###add triple loss\n",
    "            for index, logit in enumerate(logits):\n",
    "                score = logits_proto[index]\n",
    "                preindex = labels[index]\n",
    "                maxscore = score[preindex]\n",
    "                size = score.shape[0]\n",
    "                maxsecondmax = [maxscore]\n",
    "                secondmax = -100000\n",
    "                for j in range(size):\n",
    "                    if j != preindex and score[j] > secondmax:\n",
    "                        secondmax = score[j]\n",
    "                maxsecondmax.append(secondmax)\n",
    "                for j in range(size):\n",
    "                    if j != preindex and maxscore - score[j] < threshold:\n",
    "                        maxsecondmax.append(score[j])\n",
    "                maxsecond = torch.stack(maxsecondmax, 0)\n",
    "                maxsecond = torch.unsqueeze(maxsecond, 0)\n",
    "                la = torch.tensor([0]).to(config['device'])\n",
    "                loss3 += criterion(maxsecond, la)\n",
    "            loss3 /= logits.shape[0]\n",
    "\n",
    "            loss5 = torch.tensor(0.0).to(config['device'])\n",
    "\n",
    "            for index, logit in enumerate(logits):\n",
    "                preindex = labels[index]\n",
    "                if preindex in model.haveseenrelations:\n",
    "                    loss5 += mseloss(softmax(rep[index]), softmax(model.prototypes[preindex]))\n",
    "            loss5 /= logits.shape[0] \n",
    "\n",
    "            loss6 = torch.tensor(0.0).to(config['device'])\n",
    "            for index, logit in enumerate(logits):\n",
    "                preindex = labels[index]\n",
    "                if preindex in model.haveseenrelations:\n",
    "                    best_distrbution = model.mem_forward_update(rep[index].view(1, -1), model.bestproto)\n",
    "                    current_distrbution = model.mem_forward_update(model.prototypes[preindex].view(1, -1), model.bestproto)\n",
    "                    loss6 += mseloss(best_distrbution, current_distrbution)\n",
    "            loss6 /= logits.shape[0]\n",
    "            \n",
    "             # --- add info_nce loss ---\n",
    "            prototypes = model.prototypes.clone()\n",
    "            infoNCE_loss = 0\n",
    "            try:\n",
    "                for i in range(rep.shape[0]):\n",
    "                    neg_prototypes = [prototypes[rel_id] for rel_id in seen_relations_ids if rel_id != labels[i].item()]\n",
    "                    neg_prototypes = torch.stack(neg_prototypes)\n",
    "                    neg_prototypes.requires_grad_ = False\n",
    "                    neg_prototypes = neg_prototypes.squeeze() # [num_neg_prototypes, dim]\n",
    "\n",
    "                    f_pos = model.sentence_encoder.infoNCE_f(lmhead_output[i],rep[i] , temperature = config['infonce_temperature'])\n",
    "                    f_neg = model.sentence_encoder.infoNCE_f(lmhead_output[i],neg_prototypes , temperature = config['infonce_temperature'])\n",
    "                    f_concat = torch.cat([f_pos.unsqueeze(0),f_neg],dim = 0)\n",
    "\n",
    "                    infoNCE_loss += -torch.log(softmax(f_concat/abs(f_concat).max())[0])\n",
    "            except Exception as e:\n",
    "                print(e.with_traceback())\n",
    "                print(\"no infoNCE_loss\")\n",
    "            infoNCE_loss /= rep.shape[0]\n",
    "\n",
    "            # --- add info_nce loss ---\n",
    "\n",
    "            # --- add mlm loss ---\n",
    "            mlm_labels = labels + 30522 - 1\n",
    "            mlm_labels = mlm_labels.to(config['device'])\n",
    "            mlm_loss = criterion(lmhead_output,mlm_labels)\n",
    "            # --- add mlm loss ---\n",
    "\n",
    "\n",
    "\n",
    "            loss = loss1 * lossesfactor1 + loss2 * lossesfactor2 + loss3 * lossesfactor3 + loss4 * lossesfactor4  + loss5 * lossesfactor5 + loss6 * lossesfactor6 + infoNCE_loss * config['infonce_lossfactor'] + mlm_loss * config['mlm_lossfactor']\n",
    "            loss.backward()\n",
    "            losses1.append(loss1.item())\n",
    "            losses2.append(loss2.item())\n",
    "            losses3.append(loss3.item())\n",
    "            losses4.append(loss4.item())\n",
    "            losses5.append(loss5.item())\n",
    "            losses6.append(loss6.item())\n",
    "            wandb.log({\"Loss1\": loss1.item(), \"Loss2\": loss2.item(), \"Loss3\": loss3.item(), \"Loss4\": loss4.item(), \"Loss5\": loss5.item(), \"Loss6\": loss6.item(), \"InfoNCE_loss\": infoNCE_loss.item(), \"mlm_loss\": mlm_loss.item()})\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])#cxd\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--task\" , default=\"tacred\" , type=str)\n",
    "    parser.add_argument(\"--shot\" , default=5 , type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.task == \"tacred\":\n",
    "        f = open(\"config/config_tacred.json\", \"r\")\n",
    "    elif args.task == \"fewrel\":\n",
    "        f = open(\"config/config_fewrel_5and10.json\", \"r\")\n",
    "    else:\n",
    "        raise ValueError(\"task must be tacred or fewrel\")\n",
    "    \n",
    "    config = json.loads(f.read())\n",
    "    f.close()\n",
    "\n",
    "    if args.task == \"fewrel\":\n",
    "        config['relation_file'] = \"data/fewrel/relation_name.txt\"\n",
    "        config['rel_index'] = \"data/fewrel/rel_index.npy\"\n",
    "        config['rel_feature'] = \"data/fewrel/rel_feature.npy\"\n",
    "        config['rel_des_file'] = \"data/fewrel/relation_description.txt\"\n",
    "        config['num_of_relation'] = 80\n",
    "        if args.shot == 5:\n",
    "            print('fewrel 5 shot')\n",
    "            config['rel_cluster_label'] = \"data/fewrel/CFRLdata_10_100_10_5/rel_cluster_label_0.npy\"\n",
    "            config['training_file'] = \"data/fewrel/CFRLdata_10_100_10_5/train_0.txt\"\n",
    "            config['valid_file'] = \"data/fewrel/CFRLdata_10_100_10_5/valid_0.txt\"\n",
    "            config['test_file'] = \"data/fewrel/CFRLdata_10_100_10_5/test_0.txt\"\n",
    "        elif args.shot == 10:\n",
    "            config['rel_cluster_label'] = \"data/fewrel/CFRLdata_10_100_10_10/rel_cluster_label_0.npy\"\n",
    "            config['training_file'] = \"data/fewrel/CFRLdata_10_100_10_10/train_0.txt\"\n",
    "            config['valid_file'] = \"data/fewrel/CFRLdata_10_100_10_10/valid_0.txt\"\n",
    "            config['test_file'] = \"data/fewrel/CFRLdata_10_100_10_10/test_0.txt\"\n",
    "        else:\n",
    "            print('fewrel 2 shot')\n",
    "            config['rel_cluster_label'] = \"data/fewrel/CFRLdata_10_100_10_2/rel_cluster_label_0.npy\"\n",
    "            config['training_file'] = \"data/fewrel/CFRLdata_10_100_10_2/train_0.txt\"\n",
    "            config['valid_file'] = \"data/fewrel/CFRLdata_10_100_10_2/valid_0.txt\"\n",
    "            config['test_file'] = \"data/fewrel/CFRLdata_10_100_10_2/test_0.txt\"\n",
    "    else:\n",
    "        config['relation_file'] = \"data/tacred/relation_name.txt\"\n",
    "        config['rel_index'] = \"data/tacred/rel_index.npy\"\n",
    "        config['rel_feature'] = \"data/tacred/rel_feature.npy\"\n",
    "        config['num_of_relation'] = 41\n",
    "        if args.shot == 5:\n",
    "            config['rel_cluster_label'] = \"data/tacred/CFRLdata_10_100_10_5/rel_cluster_label_0.npy\"\n",
    "            config['training_file'] = \"data/tacred/CFRLdata_10_100_10_5/train_0.txt\"\n",
    "            config['valid_file'] = \"data/tacred/CFRLdata_10_100_10_5/valid_0.txt\"\n",
    "            config['test_file'] = \"data/tacred/CFRLdata_10_100_10_5/test_0.txt\"\n",
    "        else:\n",
    "            config['rel_cluster_label'] = \"data/tacred/CFRLdata_10_100_10_10/rel_cluster_label_0.npy\"\n",
    "            config['training_file'] = \"data/tacred/CFRLdata_10_100_10_10/train_0.txt\"\n",
    "            config['valid_file'] = \"data/tacred/CFRLdata_10_100_10_10/valid_0.txt\"\n",
    "            config['test_file'] = \"data/tacred/CFRLdata_10_100_10_10/test_0.txt\"\n",
    "\n",
    "        \n",
    "    config['device'] = torch.device('cuda' if torch.cuda.is_available() and config['use_gpu'] else 'cpu')\n",
    "    config['n_gpu'] = torch.cuda.device_count()\n",
    "    config['batch_size_per_step'] = int(config['batch_size'] / config[\"gradient_accumulation_steps\"])\n",
    "    config['neg_sampling'] = False\n",
    "\n",
    "\n",
    "    config['device'] = torch.device('cuda' if torch.cuda.is_available() and config['use_gpu'] else 'cpu')\n",
    "    config['n_gpu'] = torch.cuda.device_count()\n",
    "    config['batch_size_per_step'] = int(config['batch_size'] / config[\"gradient_accumulation_steps\"])\n",
    "    config['neg_sampling'] = False\n",
    "\n",
    "    config['first_task_k-way'] = 10\n",
    "    config['k-shot'] = 5\n",
    "    donum = 1\n",
    "    epochs = 1\n",
    "    threshold=0.1\n",
    "\n",
    "    wandb.init(\n",
    "    project = 'DATN',\n",
    "    name = f\"ConPL_{args.task}_{args.shot}_{config['infonce_lossfactor']}_{config['mlm_lossfactor']}\",\n",
    "    config = {\n",
    "        'name': \"ConPL\",\n",
    "        \"task\" : args.task,\n",
    "        \"shot\" : \"5\",\n",
    "        \"infonce_lossfactor\" : config['infonce_lossfactor'],\n",
    "        \"mlm_lossfactor\" : config['mlm_lossfactor']\n",
    "    }\n",
    ")\n",
    "\n",
    "    for m in range(donum):\n",
    "        print(m)\n",
    "\n",
    "        encoderforbase = BERTMLMSentenceEncoderPrompt(config)\n",
    "        \n",
    "        #freeze lm head --------------\n",
    "        for name,param in encoderforbase.bert.named_parameters():\n",
    "            if 'cls' in name:\n",
    "                param.requires_grad = False\n",
    "        #freeze lm head --------------\n",
    "\n",
    "        original_vocab_size = len(list(encoderforbase.tokenizer.get_vocab()))\n",
    "        print('Vocab size: %d'%original_vocab_size)\n",
    "        if config[\"prompt\"] == \"hard-complex\":\n",
    "            template = 'the relation between e1 and e2 is mask . '\n",
    "            print('Template: %s'%template)\n",
    "        elif config[\"prompt\"] == \"hard-simple\":\n",
    "            template = 'e1 mask e2 . '\n",
    "            print('Template: %s'%template)\n",
    "        else:\n",
    "            template = None\n",
    "            print(\"no use soft prompt.\")\n",
    "        \n",
    "        sampler = data_sampler_bert_prompt_deal_first_task_sckd(config, encoderforbase.tokenizer, template)\n",
    "        modelforbase = proto_softmax_layer_bertmlm_prompt(encoderforbase, num_class=len(sampler.id2rel), id2rel=sampler.id2rel, drop=0, config=config)\n",
    "        modelforbase = modelforbase.to(config[\"device\"])\n",
    "\n",
    "        sequence_results = []\n",
    "        sequence_results_average = []\n",
    "        result_whole_test = []\n",
    "        result_whole_test_average = []\n",
    "        all_allresults_array = []\n",
    "\n",
    "        fr_all = []\n",
    "        distored_all = []\n",
    "        for rou in range(6): #6 times different seeds to get average results\n",
    "\n",
    "            num_class = len(sampler.id2rel)\n",
    "            print('random_seed: ' + str(config['random_seed'] + 100 * rou))\n",
    "            set_seed(config, config['random_seed'] + 100 * rou)\n",
    "            sampler.set_seed(config['random_seed'] + 100 * rou)\n",
    "\n",
    "            #cxd\n",
    "            proto_acc = [[] for i in range(num_class)]\n",
    "            proto_embedding = [[] for i in range(num_class)]\n",
    "\n",
    "            mem_set = {} ####  mem_set = {rel_id:{'0':[positive samples],'1':[negative samples]}} 换5个head 换5个tail\n",
    "            mem_relations = []   ###not include relation of current task\n",
    "\n",
    "            past_relations = []\n",
    "\n",
    "            savetest_all_data = None\n",
    "            saveseen_relations = []\n",
    "\n",
    "            proto_memory = []\n",
    "\n",
    "            for i in range(len(sampler.id2rel)):\n",
    "                proto_memory.append([sampler.id2rel_pattern[i]])\n",
    "            # print('proto_memory', proto_memory)\n",
    "            oneseqres = []\n",
    "            whole_acc = []\n",
    "            allresults_list = []\n",
    "            ##################################\n",
    "            whichdataselecct = 1\n",
    "            ifnorm = True\n",
    "            ##################################\n",
    "            id2rel = sampler.id2rel\n",
    "            rel2id = sampler.rel2id\n",
    "            seen_test_data_by_task = []\n",
    "            for steps, (training_data, valid_data, test_data,test_all_data, seen_relations,current_relations) in enumerate(sampler):\n",
    "                print('current training data num: ' + str(len(training_data)))\n",
    "                seen_relations_ids = [rel2id[relation] + 1 for relation in seen_relations] # seen relation (list of int) (include relation of current task)\n",
    "                current_relations_ids = [rel2id[relation] + 1 for relation in current_relations] # current relation (list of int)\n",
    "                \n",
    "                seen_test_data_by_task.append(test_data)\n",
    "                savetest_all_data = [] # test data of all tasks (array of shape 8000x16)\n",
    "                for tmp in test_all_data:\n",
    "                    savetest_all_data.extend(tmp)\n",
    "                saveseen_relations = seen_relations\n",
    "\n",
    "                currentnumber = len(current_relations)\n",
    "                print('current relations num: '+ str(currentnumber))\n",
    "                divide_train_set = {}\n",
    "                for relation in current_relations_ids:\n",
    "                    divide_train_set[relation] = []  ##int\n",
    "                for data in training_data:\n",
    "                    divide_train_set[data[0]].append(data)\n",
    "                print('current divide num: '+ str(len(divide_train_set)))\n",
    "\n",
    "\n",
    "                current_proto = get_memory(config, modelforbase, proto_memory) #这时候的current_proto是根据81个关系的名称输入模型之中得到的81个fake embedding：[81, 200]\n",
    "                select_data_all(mem_set, proto_memory, config, modelforbase, divide_train_set,\n",
    "                            config['rel_memory_size'], current_relations_ids, 0)  ##config['rel_memory_size'] == 1 \n",
    "                            #proto_memory中的样本根据divide_train_set(training_data划分对应类)来增加每个类对应K个样本，mem_set[thisrel] = {'0': [], '1': {'h': [], 't': []}} 0放正样例，1放负样例，datatype=3\n",
    "\n",
    "                ###add to mem data\n",
    "                mem_set_length = {}\n",
    "                proto_memory_length = []\n",
    "                for i in range(len(proto_memory)):\n",
    "                    proto_memory_length.append(len(proto_memory[i]))\n",
    "                for key in mem_set.keys():\n",
    "                    mem_set_length[key] = len(mem_set[key]['0'])\n",
    "                print(\"mem_set_length\", mem_set_length)\n",
    "                print(\"proto_memory_length\", proto_memory_length)\n",
    "\n",
    "                for j in range(1):\n",
    "                    current_proto = get_memory(config, modelforbase, proto_memory)\n",
    "                    modelforbase = train_model_with_hard_neg(config, modelforbase, mem_set, training_data, epochs,\n",
    "                                                                current_proto, tokenizer = encoderforbase.tokenizer,seen_relation_ids=seen_relations_ids, ifnegtive=0,threshold=threshold, use_loss5=False)\n",
    "                \n",
    "                select_data(mem_set, proto_memory, config, modelforbase, divide_train_set,\n",
    "                            config['rel_memory_size'], current_relations_ids, 0)  ##config['rel_memory_size'] == 1 \n",
    "                \n",
    "                mem_set_length = {}\n",
    "                proto_memory_length = []\n",
    "                for i in range(len(proto_memory)):\n",
    "                    proto_memory_length.append(len(proto_memory[i]))\n",
    "                for key in mem_set.keys():\n",
    "                    mem_set_length[key] = len(mem_set[key]['0'])\n",
    "                print(\"mem_set_length\", mem_set_length)\n",
    "                print(\"proto_memory_length\", proto_memory_length)\n",
    "                for j in range(1):\n",
    "                    current_proto = get_memory(config, modelforbase, proto_memory)\n",
    "                    modelforbase = train_model_with_hard_neg(config, modelforbase, mem_set, training_data, epochs,\n",
    "                                                                current_proto, tokenizer = encoderforbase.tokenizer,seen_relation_ids=seen_relations_ids, ifnegtive=0,threshold=threshold)\n",
    "                \n",
    "                #add train memory\n",
    "                current_proto = get_memory(config, modelforbase, proto_memory)\n",
    "                modelforbase = train_memory(config, modelforbase, mem_set, training_data, epochs*3, current_proto, original_vocab_size,ifusemem= True,seen_relation_ids=seen_relations_ids, threshold=threshold)\n",
    "\n",
    "                \n",
    "                current_proto = get_memory(config, modelforbase, proto_memory)\n",
    "                modelforbase.set_memorized_prototypes_midproto(current_proto)\n",
    "                modelforbase.save_bestproto(current_relations_ids)#save bestproto\n",
    "                mem_relations.extend(current_relations_ids)\n",
    "\n",
    "                currentalltest = []\n",
    "                for mm in range(len(test_data)):\n",
    "                    currentalltest.extend(test_data[mm])\n",
    "\n",
    "                #compute mean accuarcy\n",
    "                results = [eval_model(config, modelforbase, item, mem_relations,seen_relations_ids) for item in seen_test_data_by_task] # results of all previous task + this task after training on current task\n",
    "                allresults_list.append(results)\n",
    "                results_average = np.array(results).mean() # average accuracy of all tasks after training on current task\n",
    "                wandb.log({f\"Round {rou} Average Accuracy\": results_average})\n",
    "                whole_acc.append(results_average)\n",
    "\n",
    "                #compute whole accuarcy\n",
    "                seen_test_set = []\n",
    "                for seen_relation in seen_relations_ids:\n",
    "                    seen_test_set.extend(test_all_data[seen_relation - 1]) # test_all_data is a list of test data of all relation (test_all_data[0] is test data of relation 1])\n",
    "                thisstepres = eval_model(config, modelforbase, seen_test_set, mem_relations,seen_relations_ids) # combine all test data of all tasks and evaluate\n",
    "                oneseqres.append(thisstepres)\n",
    "\n",
    "            sequence_results.append(np.array(oneseqres)) # combine all test data of all tasks and evaluate\n",
    "            sequence_results_average.append(np.array(whole_acc)) # evaluate each task and average\n",
    "\n",
    "            allres = eval_model(config, modelforbase, savetest_all_data, saveseen_relations,seen_relations_ids) # eval on all test data of all tasks\n",
    "            result_whole_test.append(allres)\n",
    "\n",
    "            print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "            print(\"after one epoch allres whole:\\t\" + str(allres))\n",
    "            print(result_whole_test)\n",
    "\n",
    "            allresults = [eval_model(config, modelforbase, item, num_class,seen_relations_ids) for item in seen_test_data_by_task]\n",
    "            allresults_average = np.array(allresults).mean()\n",
    "            result_whole_test_average.append(allresults_average)\n",
    "            print(\"after one epoch allres average:\\t\" + str(allresults))\n",
    "            print(result_whole_test_average)\n",
    "\n",
    "\n",
    "            modelforbase = modelforbase.to('cpu')\n",
    "            del modelforbase\n",
    "            gc.collect()\n",
    "            if config['device'] == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            encoderforbase = BERTMLMSentenceEncoderPrompt(config)\n",
    "            modelforbase = proto_softmax_layer_bertmlm_prompt(encoderforbase, num_class=len(sampler.id2rel), id2rel=sampler.id2rel, drop=0, config=config)\n",
    "            modelforbase = modelforbase.to(config[\"device\"])\n",
    "        print(\"Final result: whole!\")\n",
    "        print(result_whole_test)\n",
    "        for one in sequence_results:\n",
    "            for item in one:\n",
    "                sys.stdout.write('%.4f, ' % item)\n",
    "            print('')\n",
    "        avg_result_all_test = np.average(sequence_results, 0)\n",
    "        for one in avg_result_all_test:\n",
    "            sys.stdout.write('%.4f, ' % one)\n",
    "        print('')\n",
    "        print(\"Final result: average!\")\n",
    "        print(result_whole_test_average)\n",
    "        for one in sequence_results_average:\n",
    "            for item in one:\n",
    "                sys.stdout.write('%.4f, ' % item)\n",
    "            print('')\n",
    "        avg_result_all_test_average = np.average(sequence_results_average, 0)\n",
    "        for one in avg_result_all_test_average:\n",
    "            sys.stdout.write('%.4f, ' % one)\n",
    "        print('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
